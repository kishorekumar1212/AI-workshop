{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmQC7zfFhgP_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3fcc191-ed34-4ccd-fa06-ed7f99aec60a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a statement (or type 'exit' to quit): this is very bad\n",
            "Predicted Sentiment: negative (Confidence: 86.01%)\n",
            "Enter a statement (or type 'exit' to quit): the food is good , packaging is worst\n",
            "Predicted Sentiment: neutral (Confidence: 47.32%)\n",
            "Enter a statement (or type 'exit' to quit): the sentence is b=negative\n",
            "Predicted Sentiment: negative (Confidence: 38.20%)\n",
            "Enter a statement (or type 'exit' to quit): positive\n",
            "Predicted Sentiment: positive (Confidence: 38.41%)\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch import softmax\n",
        "import torch\n",
        "\n",
        "# Load the pretrained model and tokenizer from Hugging Face\n",
        "model_name = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "# Function to predict sentiment\n",
        "def predict_sentiment(text):\n",
        "    # Encode the text to BERT's required format\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "\n",
        "    # Perform the forward pass through the model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Apply softmax to get probabilities for each sentiment class (0-4)\n",
        "    probs = softmax(outputs.logits, dim=-1)\n",
        "\n",
        "    # Get the sentiment with the highest probability\n",
        "    sentiment = torch.argmax(probs).item()\n",
        "\n",
        "    # Map the numerical sentiment to simplified human-readable sentiment labels\n",
        "    if sentiment == 0 or sentiment == 1:\n",
        "        sentiment_label = \"negative\"\n",
        "    elif sentiment == 2:\n",
        "        sentiment_label = \"neutral\"\n",
        "    else:\n",
        "        sentiment_label = \"positive\"\n",
        "\n",
        "    return sentiment_label, probs[0][sentiment].item()\n",
        "\n",
        "# User input loop\n",
        "while True:\n",
        "    user_input = input(\"Enter a statement (or type 'exit' to quit): \")\n",
        "\n",
        "    if user_input.lower() == 'exit':\n",
        "        print(\"Exiting the program.\")\n",
        "        break\n",
        "\n",
        "    sentiment, confidence = predict_sentiment(user_input)\n",
        "    print(f\"Predicted Sentiment: {sentiment} (Confidence: {confidence*100:.2f}%)\")\n",
        "\\"
      ]
    }
  ]
}